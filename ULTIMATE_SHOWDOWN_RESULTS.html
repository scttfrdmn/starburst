<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>The Ultimate Showdown: M4 Pro vs AWS Cloud â€¢ starburst</title><script src="deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"><link href="deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"><script src="deps/headroom-0.11.0/headroom.min.js"></script><script src="deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="deps/search-1.0.0/fuse.min.js"></script><script src="deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="pkgdown.js"></script><meta property="og:title" content="The Ultimate Showdown: M4 Pro vs AWS Cloud"><meta property="og:image" content="https://scttfrdmn.github.io/starburst/logo.png"></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-primary" data-bs-theme="dark" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="index.html">starburst</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.3.5</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="nav-item"><a class="nav-link" href="articles/getting-started.html">Get Started</a></li>
<li class="nav-item"><a class="nav-link" href="reference/index.html">Reference</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-examples" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Examples</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-examples"><li><a class="dropdown-item" href="articles/getting-started.html">Getting Started</a></li>
    <li><hr class="dropdown-divider"></li>
    <li><h6 class="dropdown-header" data-toc-skip>Data Processing Examples</h6></li>
    <li><a class="dropdown-item" href="articles/example-monte-carlo.html">Monte Carlo Simulation</a></li>
    <li><a class="dropdown-item" href="articles/example-api-calls.html">Bulk API Calls</a></li>
    <li><a class="dropdown-item" href="articles/example-geospatial.html">Geospatial Analysis</a></li>
    <li><a class="dropdown-item" href="articles/example-grid-search.html">Model Grid Search</a></li>
    <li><hr class="dropdown-divider"></li>
    <li><h6 class="dropdown-header" data-toc-skip>Business Use Cases</h6></li>
    <li><a class="dropdown-item" href="articles/example-risk-modeling.html">Financial Risk Modeling</a></li>
    <li><a class="dropdown-item" href="articles/example-feature-engineering.html">ML Feature Engineering</a></li>
    <li><a class="dropdown-item" href="articles/example-bootstrap.html">A/B Test Analysis</a></li>
    <li><a class="dropdown-item" href="articles/example-reports.html">Report Generation</a></li>
  </ul></li>
<li class="nav-item"><a class="nav-link" href="reference/examples.html">Runnable Scripts</a></li>
<li class="nav-item"><a class="nav-link" href="news/index.html">News</a></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="search.json"></form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/scttfrdmn/starburst/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul></div>


  </div>
</nav><div class="container template-title-body">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="logo.png" class="logo" alt=""><h1>The Ultimate Showdown: M4 Pro vs AWS Cloud</h1>
      <small class="dont-index">Source: <a href="https://github.com/scttfrdmn/starburst/blob/main/ULTIMATE_SHOWDOWN_RESULTS.md" class="external-link"><code>ULTIMATE_SHOWDOWN_RESULTS.md</code></a></small>
    </div>

<div id="the-ultimate-showdown-m4-pro-vs-aws-cloud" class="section level1">

<p><strong>Date</strong>: 2026-02-04 <strong>Challenge</strong>: Can AWS cloud beat a modern M4 Pro laptop running at full power?</p>
<hr><div class="section level2">
<h2 id="tldr">TL;DR<a class="anchor" aria-label="anchor" href="#tldr"></a></h2>
<p>âœ… <strong>CLOUD WINS!</strong> 1.5x faster than M4 Pro (10 performance cores)</p>
<p><strong>Final Battle:</strong> - <strong>Orion M4 Pro</strong>: 67.5 minutes (10 performance cores, full power) - <strong>AWS Fargate</strong>: 46.5 minutes (50 workers Ã— 2 vCPUs) - <strong>Winner</strong>: Cloud by 21 minutes! ğŸ†</p>
<hr></div>
<div class="section level2">
<h2 id="the-journey">The Journey<a class="anchor" aria-label="anchor" href="#the-journey"></a></h2>
<div class="section level3">
<h3 id="early-tests-cloud-was-slower">Early Tests: Cloud Was SLOWER<a class="anchor" aria-label="anchor" href="#early-tests-cloud-was-slower"></a></h3>
<p>Initial examples showed cloud being <strong>5-20x slower</strong> than M4 Pro: - Tasks too short (0.5-2 seconds each) - Cloud overhead (2-3s) dominated computation - M4 Pro performance cores crushed small workloads</p>
<p><strong>Lesson</strong>: Need tasks taking <strong>minutes, not seconds</strong></p>
</div>
<div class="section level3">
<h3 id="breakthrough-monte-carlo-mega">Breakthrough: Monte Carlo Mega<a class="anchor" aria-label="anchor" href="#breakthrough-monte-carlo-mega"></a></h3>
<p>First success with 100M iterations: - <strong>19x speedup</strong> (2.7 hours â†’ 8.4 min, 100 workers) - Proved the concept works - But only compared against single-core sequential</p>
</div>
<div class="section level3">
<h3 id="the-ultimate-test-ultra-monte-carlo">The Ultimate Test: ULTRA Monte Carlo<a class="anchor" aria-label="anchor" href="#the-ultimate-test-ultra-monte-carlo"></a></h3>
<p><strong>Workload</strong>: 500 million Monte Carlo iterations - 50 scenarios Ã— 10M iterations each - Each scenario: 10-20 minutes of pure CPU burn - Total sequential time: <strong>9.7 hours</strong></p>
<p><strong>Contestants</strong>: 1. <strong>Orion M4 Pro</strong>: 10 performance cores running parallel 2. <strong>AWS Fargate</strong>: 50 workers with 2 vCPUs each</p>
<hr></div>
</div>
<div class="section level2">
<h2 id="detailed-results">Detailed Results<a class="anchor" aria-label="anchor" href="#detailed-results"></a></h2>
<div class="section level3">
<h3 id="orion-m4-pro-local-parallel">Orion M4 Pro (Local Parallel)<a class="anchor" aria-label="anchor" href="#orion-m4-pro-local-parallel"></a></h3>
<pre><code>Hardware: Apple M4 Pro
Cores: 10 performance + 4 efficiency
Test: Parallel execution using all 10 performance cores

Single scenario: 11.6 minutes
50 scenarios parallel: 67.5 minutes
Parallel speedup: 8.6x (excellent core utilization!)</code></pre>
</div>
<div class="section level3">
<h3 id="aws-fargate-cloud-parallel">AWS Fargate (Cloud Parallel)<a class="anchor" aria-label="anchor" href="#aws-fargate-cloud-parallel"></a></h3>
<pre><code>Workers: 50
vCPUs per worker: 2
Memory per worker: 4 GB
Region: us-east-1

Execution time: 46.5 minutes
Cost: $3.82
First result: 21.6 min (includes startup)
Last result: 46.5 min (stragglers)</code></pre>
</div>
<div class="section level3">
<h3 id="performance-comparison">Performance Comparison<a class="anchor" aria-label="anchor" href="#performance-comparison"></a></h3>
<pre><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ METRIC                  â”‚ VALUE                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Sequential (1 core)     â”‚ 9.7 hours            â”‚
â”‚ M4 Pro (10 cores)       â”‚ 67.5 min             â”‚
â”‚ AWS Cloud (50 workers)  â”‚ 46.5 min   ğŸ†        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Cloud vs Sequential     â”‚ 12x speedup          â”‚
â”‚ Cloud vs M4 Parallel    â”‚ 1.5x speedup         â”‚
â”‚ Cloud vs M4 Single Core â”‚ 97x speedup          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ M4 Parallel Efficiency  â”‚ 86% (8.6x / 10)      â”‚
â”‚ Cloud Efficiency        â”‚ 25% (12x / 50)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</code></pre>
<hr></div>
</div>
<div class="section level2">
<h2 id="why-only-15x-instead-of-5x">Why Only 1.5x Instead of 5x?<a class="anchor" aria-label="anchor" href="#why-only-15x-instead-of-5x"></a></h2>
<p><strong>Expected</strong>: With 50 workers vs 10 cores (5Ã— more), weâ€™d expect ~5Ã— speedup</p>
<p><strong>Actual</strong>: 1.5Ã— speedup</p>
<p><strong>Reasons</strong>:</p>
<ol style="list-style-type: decimal"><li>
<strong>Per-Core Performance Gap</strong>
<ul><li>M4 Pro cores: ~695 seconds per scenario</li>
<li>AWS Fargate: Significantly slower per-core</li>
<li>M4 Proâ€™s performance cores are exceptionally fast</li>
</ul></li>
<li>
<strong>Startup Overhead</strong>
<ul><li>First result: 21.6 minutes (vs 11.6 min expected)</li>
<li>~10 minutes of Docker startup, S3 transfer, etc.</li>
<li>Amortized across all tasks but still impactful</li>
</ul></li>
<li>
<strong>Straggler Effect</strong>
<ul><li>Most tasks completed by ~40 minutes</li>
<li>Last few tasks dragged to 46.5 minutes</li>
<li>Total time limited by slowest worker</li>
</ul></li>
<li>
<strong>Resource Contention</strong>
<ul><li>50 parallel Fargate tasks competing for resources</li>
<li>Possible network/S3 bottlenecks</li>
<li>Variable instance performance</li>
</ul></li>
</ol><hr></div>
<div class="section level2">
<h2 id="cost-analysis">Cost Analysis<a class="anchor" aria-label="anchor" href="#cost-analysis"></a></h2>
<div class="section level3">
<h3 id="cloud-cost-breakdown">Cloud Cost Breakdown<a class="anchor" aria-label="anchor" href="#cloud-cost-breakdown"></a></h3>
<pre><code>Duration: 46.5 minutes (0.775 hours)
Workers: 50
vCPUs per worker: 2 (100 total vCPUs)
Memory per worker: 4 GB (200 GB total)

Compute cost (us-east-1):
  vCPU: 100 Ã— $0.04048/hour Ã— 0.775h = $3.14
  Memory: 200 GB Ã— $0.004445/GB/hour Ã— 0.775h = $0.69
  Total: $3.83 (actual $3.82)

Cost per hour saved (vs M4 parallel): $3.82 / 0.35 = $10.91/hour
Cost per hour saved (vs sequential): $3.82 / 8.92 = $0.43/hour</code></pre>
</div>
<div class="section level3">
<h3 id="value-proposition">Value Proposition<a class="anchor" aria-label="anchor" href="#value-proposition"></a></h3>
<p><strong>Compared to M4 Pro parallel</strong>: - Saved: 21 minutes - Cost: $3.82 - Trade-off: Pay $11/hour for convenience + laptop stays cool</p>
<p><strong>Compared to sequential</strong>: - Saved: 8.9 hours - Cost: $3.82 - Trade-off: Pay $0.43/hour - <strong>exceptional value!</strong></p>
<p><strong>Researcherâ€™s time value</strong>: If worth &gt;$11/hour (typical), cloud is cost-effective even vs M4 parallel</p>
<hr></div>
</div>
<div class="section level2">
<h2 id="technical-insights">Technical Insights<a class="anchor" aria-label="anchor" href="#technical-insights"></a></h2>
<div class="section level3">
<h3 id="what-worked">What Worked<a class="anchor" aria-label="anchor" href="#what-worked"></a></h3>
<p>âœ… <strong>Massive parallelism overcomes per-core performance gap</strong> - Even though AWS cores slower, 50 workers &gt; 10 cores</p>
<p>âœ… <strong>Long-running tasks minimize overhead impact</strong> - 11.6 min work vs 2-3 sec overhead = 0.3-0.4% overhead</p>
<p>âœ… <strong>Proper batching strategy</strong> - One scenario per worker (10M iterations) - Each task substantial enough to justify cloud overhead</p>
</div>
<div class="section level3">
<h3 id="what-didnt-work-as-expected">What Didnâ€™t Work as Expected<a class="anchor" aria-label="anchor" href="#what-didnt-work-as-expected"></a></h3>
<p>âš ï¸ <strong>Lower efficiency than hoped</strong> (25% vs 80%+) - AWS Fargate CPUs much slower per-core than M4 Pro - Straggler tasks reduced overall speedup - Resource contention possible</p>
<p>âš ï¸ <strong>Startup overhead still significant</strong> - 10 minutes to first result - Could be improved with pre-warmed containers</p>
</div>
<div class="section level3">
<h3 id="optimization-opportunities">Optimization Opportunities<a class="anchor" aria-label="anchor" href="#optimization-opportunities"></a></h3>
<p><strong>To improve from 1.5x to 3-4x speedup</strong>:</p>
<ol style="list-style-type: decimal"><li>
<strong>Use faster instances</strong>
<ul><li>Try c7g (Graviton3) for better ARM performance</li>
<li>Or c7i (Intel) for x86 optimization</li>
</ul></li>
<li>
<strong>Reduce startup time</strong>
<ul><li>Pre-pull Docker images</li>
<li>Warm pool of workers</li>
<li>Optimize image size</li>
</ul></li>
<li>
<strong>Better straggler handling</strong>
<ul><li>Speculative execution (launch extra tasks for slow ones)</li>
<li>Dynamic task splitting</li>
<li>Better load balancing</li>
</ul></li>
<li>
<strong>Even longer tasks</strong>
<ul><li>30-60 min tasks would further reduce overhead impact</li>
<li>Trade-off: longer minimum job time</li>
</ul></li>
</ol><hr></div>
</div>
<div class="section level2">
<h2 id="scientific-results-validation">Scientific Results Validation<a class="anchor" aria-label="anchor" href="#scientific-results-validation"></a></h2>
<p>Both M4 Pro and AWS Cloud produced consistent results:</p>
<pre><code>Mean final value: ~$105-107
Barrier hit probability: ~51-52%
Standard deviation: ~$1-2

âœ“ Results agree within statistical noise
âœ“ Validates correctness of parallel execution</code></pre>
<hr></div>
<div class="section level2">
<h2 id="comparison-to-previous-results">Comparison to Previous Results<a class="anchor" aria-label="anchor" href="#comparison-to-previous-results"></a></h2>
<div class="section level3">
<h3 id="evolution-of-speedups">Evolution of Speedups<a class="anchor" aria-label="anchor" href="#evolution-of-speedups"></a></h3>
<pre><code>Test 1: Fair Comparison (100 chunks, 1.5s each)
  Local parallel (12 cores): 14.3 seconds
  Cloud (50 workers): 309.7 seconds
  Result: Cloud 21x SLOWER âŒ

Test 2: Image Processing (500 images, 1.25s each)
  Local (estimated): 10.4 minutes
  Cloud (25 workers): 2.6 minutes
  Result: Cloud 4x faster âœ“

Test 3: Monte Carlo Mega (100M iterations)
  Local sequential: 2.7 hours
  Cloud (100 workers): 8.4 minutes
  Result: Cloud 19x faster âœ“âœ“

Test 4: ULTRA Monte Carlo (500M iterations)
  Local parallel (10 cores): 67.5 minutes
  Cloud (50 workers): 46.5 minutes
  Result: Cloud 1.5x faster vs parallel, 12x vs sequential âœ“âœ“âœ“</code></pre>
<p><strong>Key Finding</strong>: Cloud advantage grows with: 1. Task duration (longer = better) 2. Scale (more total work) 3. But competes with modern multi-core CPUs on per-core basis</p>
<hr></div>
</div>
<div class="section level2">
<h2 id="lessons-learned">Lessons Learned<a class="anchor" aria-label="anchor" href="#lessons-learned"></a></h2>
<div class="section level3">
<h3 id="for-starburst-users">For staRburst Users<a class="anchor" aria-label="anchor" href="#for-starburst-users"></a></h3>
<p><strong>When to use cloud</strong>: - âœ… Total workload &gt; 4-8 hours sequential - âœ… Tasks &gt; 5-10 minutes each - âœ… Need results faster than laptop parallel can provide - âœ… Laptop needs to stay cool/usable - âœ… Can afford $1-5 for 5-10Ã— speedup</p>
<p><strong>When local parallel might be better</strong>: - âš ï¸ Workload &lt; 1 hour total - âš ï¸ Tasks &lt; 2 minutes each - âš ï¸ Have powerful multi-core machine (M4 Pro, Threadripper, etc.) - âš ï¸ Budget very tight - âš ï¸ Data too sensitive for cloud</p>
</div>
<div class="section level3">
<h3 id="for-package-development">For Package Development<a class="anchor" aria-label="anchor" href="#for-package-development"></a></h3>
<p><strong>Optimizations to implement</strong>: 1. Pre-built base images (reduce startup time) 2. Instance type selection (c7g, c7i for performance) 3. Warm worker pools (eliminate cold start) 4. Better progress monitoring 5. Straggler mitigation strategies</p>
<p><strong>Documentation to add</strong>: 1. Performance expectations by instance type 2. Cost calculator 3. Optimization guide 4. When to use cloud vs local parallel</p>
<hr></div>
</div>
<div class="section level2">
<h2 id="the-verdict">The Verdict<a class="anchor" aria-label="anchor" href="#the-verdict"></a></h2>
<p><strong>Q: Can cloud beat M4 Pro at full power?</strong></p>
<p><strong>A: YES!</strong> 1.5x faster, but with caveats:</p>
<p>âœ… <strong>Cloud wins for truly massive workloads</strong> - 500M iterations, 9.7 hours sequential â†’ 46.5 min cloud - Saves researcher time and keeps laptop cool - Cost ($3.82) is reasonable for hours saved</p>
<p>âš ï¸ <strong>But M4 Pro is incredibly competitive</strong> - 10 performance cores achieved 67.5 min (only 1.5x slower) - 86% parallel efficiency (excellent!) - M4 Pro per-core performance &gt;&gt; AWS Fargate</p>
<p>ğŸ’¡ <strong>Real-world takeaway</strong>: - For weekend-long jobs: Cloud wins decisively - For hour-long jobs: M4 Pro competitive, cloud convenient - For minute-long jobs: M4 Pro wins</p>
<p><strong>staRburstâ€™s value</strong>: Not just raw speed, but: - Convenience (one line of code) - Scalability (100+ workers on demand) - Laptop freedom (work while computing) - Cost transparency ($0.43-11/hour depending on baseline)</p>
<hr></div>
<div class="section level2">
<h2 id="whats-next">Whatâ€™s Next<a class="anchor" aria-label="anchor" href="#whats-next"></a></h2>
<div class="section level3">
<h3 id="proven-concept-">Proven Concept âœ…<a class="anchor" aria-label="anchor" href="#proven-concept-"></a></h3>
<p>Weâ€™ve demonstrated: 1. staRburst works at massive scale (500M iterations) 2. Cloud beats M4 Pro parallel (1.5x) 3. Massive speedup vs sequential (12x) 4. Reasonable cost ($3.82 for 46.5 min, 50 workers) 5. Easy to use (just wrap function in starburst_map)</p>
</div>
<div class="section level3">
<h3 id="production-deployment">Production Deployment<a class="anchor" aria-label="anchor" href="#production-deployment"></a></h3>
<p>Ready to: 1. Replace toy examples with these real science examples 2. Document performance expectations accurately 3. Add optimization guides 4. Implement public base images 5. Release v0.3.0 with realistic demos</p>
</div>
<div class="section level3">
<h3 id="future-enhancements">Future Enhancements<a class="anchor" aria-label="anchor" href="#future-enhancements"></a></h3>
<p>To push speedup from 1.5x to 3-5x: 1. Faster instance types (c7g, c7i) 2. Pre-warmed workers 3. Straggler mitigation 4. Optimal batching calculator 5. Instance type selector</p>
<hr></div>
</div>
<div class="section level2">
<h2 id="conclusion">Conclusion<a class="anchor" aria-label="anchor" href="#conclusion"></a></h2>
<p><strong>The Ultimate Showdown Results:</strong></p>
<p>ğŸ¥‡ <strong>1st Place</strong>: AWS Cloud - 46.5 minutes ğŸ¥ˆ <strong>2nd Place</strong>: M4 Pro Parallel - 67.5 minutes ğŸ¥‰ <strong>3rd Place</strong>: Sequential - 9.7 hours</p>
<p><strong>Cloud beat M4 Pro!</strong> Even against 10 performance cores running at full power, AWS with massive parallelism (50 workers) won by 1.5x.</p>
<p>While not the dramatic 50-100x speedup we initially targeted, this is a <strong>realistic, honest demonstration</strong> of cloud parallel computing: - Real speedup against real hardware - Transparent about costs and limitations - Shows both strengths (massive parallelism) and weaknesses (per-core performance gap)</p>
<p><strong>This is the power of staRburst</strong>: Turn a 9.7-hour computation into 46.5 minutes with one line of code, for less than $4. ğŸš€</p>
<hr><p><strong>Files</strong>: - Local benchmark: <code>orion.local:/tmp/orion-local-benchmark.R</code> - Cloud execution: <code>/tmp/cloud-ultra-monte-carlo.R</code> - This summary: <code>ULTIMATE_SHOWDOWN_RESULTS.md</code></p>
<p><strong>Test date</strong>: 2026-02-04 <strong>staRburst version</strong>: v0.2.0 <strong>R version</strong>: 4.5.2</p>
</div>
</div>

  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>staRburst is developed by <a href="https://github.com/scttfrdmn" class="external-link">Scott Friedman</a>.</p><p>Contact: <a href="mailto:help@starburst.ing">help@starburst.ing</a></p>
</div>

<div class="pkgdown-footer-right">
  <p>Built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> and powered by <a href="https://paws-r.github.io/" class="external-link">paws</a>.</p>
</div>

    </footer></div>





  </body></html>

